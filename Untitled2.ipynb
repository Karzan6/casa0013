{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4e01fb-2250-4e6d-ad82-52626e21bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8180ac-edac-43b0-9576-9793976093c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Field</th>\n",
       "      <th>Type</th>\n",
       "      <th>Mandatory or Optional requirement (MOR)</th>\n",
       "      <th>Field Description</th>\n",
       "      <th>Schema</th>\n",
       "      <th>LCC Mapping</th>\n",
       "      <th>Schema Comments</th>\n",
       "      <th>Schema Data Rules Comment</th>\n",
       "      <th>FormatReference</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Organisation Name</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>Name of the organisation that is the asset own...</td>\n",
       "      <td>LGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Name of the Organisation's area coverage. Woul...</td>\n",
       "      <td>Name of the Organisation's area coverage.</td>\n",
       "      <td>Lincolnshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Organisation Code</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>A unique code to identify the asset owning/usi...</td>\n",
       "      <td>LGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://opendatacommunities.org/def/concept/fol...</td>\n",
       "      <td>Lincolnshire County Council:  http://opendatac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Published Date</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>Optional</td>\n",
       "      <td>Date at which the information provided is true.</td>\n",
       "      <td>LGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Include this field to show the publication dat...</td>\n",
       "      <td>https://www.w3.org/TR/NOTE-datetime</td>\n",
       "      <td>YYYY-MM-DDThh:mm:ss      eg:  2017-02-15T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Latest Data</td>\n",
       "      <td>Boolean</td>\n",
       "      <td>Optional</td>\n",
       "      <td>TRUE where the data is the latest for the indi...</td>\n",
       "      <td>LCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Duration From</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>Optional</td>\n",
       "      <td>Dataset time period start, or start of account...</td>\n",
       "      <td>LGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset time period start, or start of account...</td>\n",
       "      <td>http://calendars.wikia.com/wiki/ISO_8601</td>\n",
       "      <td>YYYY-MM-DDThh:mm:ss      eg:  2017-04-01T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Duration To</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>Optional</td>\n",
       "      <td>Dataset time period end, or end of accounting/...</td>\n",
       "      <td>LGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset time period end, or end of accounting/...</td>\n",
       "      <td>http://calendars.wikia.com/wiki/ISO_8601</td>\n",
       "      <td>YYYY-MM-DDThh:mm:ss      eg:  2017-06-30T23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Reporting Period Type</td>\n",
       "      <td>String</td>\n",
       "      <td>Mandatory</td>\n",
       "      <td>The type of time period the data record covers...</td>\n",
       "      <td>LCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The type of time period the data record covers...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eg. Financial Year, Calendar Year, Month, Quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Geo Entity Name</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>Type of geographic area</td>\n",
       "      <td>LCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://statistics.data.gov.uk/areas</td>\n",
       "      <td>County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Geo Code</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>ONS geography identifier for the geography in ...</td>\n",
       "      <td>LCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://statistics.data.gov.uk/areas</td>\n",
       "      <td>E10000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Geo Name</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>ONS geography name for the geography in which ...</td>\n",
       "      <td>LCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://statistics.data.gov.uk/areas</td>\n",
       "      <td>Lincolnshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Geo URI</td>\n",
       "      <td>String</td>\n",
       "      <td>Optional</td>\n",
       "      <td>ONS geography linked data URI for the geograph...</td>\n",
       "      <td>LCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://statistics.data.gov.uk/areas</td>\n",
       "      <td>http://statistics.data.gov.uk/doc/statistical-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>Year</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>Mandatory</td>\n",
       "      <td>Year</td>\n",
       "      <td>LGA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://calendars.wikia.com/wiki/ISO_8601</td>\n",
       "      <td>1994, or 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>CO2 Emissions</td>\n",
       "      <td>CO2 Emissions Tonnes Per Person</td>\n",
       "      <td>Number</td>\n",
       "      <td>Mandatory</td>\n",
       "      <td>Total CO2 Emissions (tonnes) per Person per Year</td>\n",
       "      <td>LCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Decimal Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset ID   Dataset Name                            Field      Type  \\\n",
       "0            8  CO2 Emissions                Organisation Name    String   \n",
       "1            8  CO2 Emissions                Organisation Code    String   \n",
       "2            8  CO2 Emissions                   Published Date  DateTime   \n",
       "3            8  CO2 Emissions                      Latest Data   Boolean   \n",
       "4            8  CO2 Emissions                    Duration From  DateTime   \n",
       "5            8  CO2 Emissions                      Duration To  DateTime   \n",
       "6            8  CO2 Emissions            Reporting Period Type    String   \n",
       "7            8  CO2 Emissions                  Geo Entity Name    String   \n",
       "8            8  CO2 Emissions                         Geo Code    String   \n",
       "9            8  CO2 Emissions                         Geo Name    String   \n",
       "10           8  CO2 Emissions                          Geo URI    String   \n",
       "11           8  CO2 Emissions                             Year  DateTime   \n",
       "12           8  CO2 Emissions  CO2 Emissions Tonnes Per Person    Number   \n",
       "\n",
       "   Mandatory or Optional requirement (MOR)  \\\n",
       "0                                 Optional   \n",
       "1                                 Optional   \n",
       "2                                 Optional   \n",
       "3                                 Optional   \n",
       "4                                 Optional   \n",
       "5                                 Optional   \n",
       "6                                Mandatory   \n",
       "7                                 Optional   \n",
       "8                                 Optional   \n",
       "9                                 Optional   \n",
       "10                                Optional   \n",
       "11                               Mandatory   \n",
       "12                               Mandatory   \n",
       "\n",
       "                                    Field Description Schema  LCC Mapping  \\\n",
       "0   Name of the organisation that is the asset own...    LGA          NaN   \n",
       "1   A unique code to identify the asset owning/usi...    LGA          NaN   \n",
       "2     Date at which the information provided is true.    LGA          NaN   \n",
       "3   TRUE where the data is the latest for the indi...    LCC          NaN   \n",
       "4   Dataset time period start, or start of account...    LGA          NaN   \n",
       "5   Dataset time period end, or end of accounting/...    LGA          NaN   \n",
       "6   The type of time period the data record covers...    LCC          NaN   \n",
       "7                             Type of geographic area    LCC          NaN   \n",
       "8   ONS geography identifier for the geography in ...    LCC          NaN   \n",
       "9   ONS geography name for the geography in which ...    LCC          NaN   \n",
       "10  ONS geography linked data URI for the geograph...    LCC          NaN   \n",
       "11                                               Year    LGA          NaN   \n",
       "12   Total CO2 Emissions (tonnes) per Person per Year    LCC          NaN   \n",
       "\n",
       "    Schema Comments                          Schema Data Rules Comment  \\\n",
       "0               NaN  Name of the Organisation's area coverage. Woul...   \n",
       "1               NaN                                                NaN   \n",
       "2               NaN  Include this field to show the publication dat...   \n",
       "3               NaN                                                NaN   \n",
       "4               NaN  Dataset time period start, or start of account...   \n",
       "5               NaN  Dataset time period end, or end of accounting/...   \n",
       "6               NaN  The type of time period the data record covers...   \n",
       "7               NaN                                                NaN   \n",
       "8               NaN                                                NaN   \n",
       "9               NaN                                                NaN   \n",
       "10              NaN                                                NaN   \n",
       "11              NaN                                                NaN   \n",
       "12              NaN                                    1 Decimal Place   \n",
       "\n",
       "                                      FormatReference  \\\n",
       "0           Name of the Organisation's area coverage.   \n",
       "1   http://opendatacommunities.org/def/concept/fol...   \n",
       "2                 https://www.w3.org/TR/NOTE-datetime   \n",
       "3                                                 NaN   \n",
       "4            http://calendars.wikia.com/wiki/ISO_8601   \n",
       "5            http://calendars.wikia.com/wiki/ISO_8601   \n",
       "6                                                 NaN   \n",
       "7                 http://statistics.data.gov.uk/areas   \n",
       "8                 http://statistics.data.gov.uk/areas   \n",
       "9                 http://statistics.data.gov.uk/areas   \n",
       "10                http://statistics.data.gov.uk/areas   \n",
       "11           http://calendars.wikia.com/wiki/ISO_8601   \n",
       "12                                                NaN   \n",
       "\n",
       "                                              Example  \n",
       "0                                        Lincolnshire  \n",
       "1   Lincolnshire County Council:  http://opendatac...  \n",
       "2   YYYY-MM-DDThh:mm:ss      eg:  2017-02-15T00:00:00  \n",
       "3                                                TRUE  \n",
       "4   YYYY-MM-DDThh:mm:ss      eg:  2017-04-01T00:00:00  \n",
       "5   YYYY-MM-DDThh:mm:ss      eg:  2017-06-30T23:59:59  \n",
       "6   eg. Financial Year, Calendar Year, Month, Quarter  \n",
       "7                                              County  \n",
       "8                                           E10000019  \n",
       "9                                        Lincolnshire  \n",
       "10  http://statistics.data.gov.uk/doc/statistical-...  \n",
       "11                                      1994, or 2017  \n",
       "12                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://lincolnshire.ckan.io/dataset/24849e1d-7c5a-46dd-a07b-ee1e308b03fb/resource/3055e89d-13fb-464f-94f0-5ed0a287ead2/download/metadata_co2emissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24f5e3-acb7-4225-9579-418046d9e366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


import pandas as pd
import os
import requests
import gzip
import io
import geopandas as gpd
from shapely.geometry import Point
from tabulate import tabulate
import re

# List of datasets to process
datasets = [
    {
        "url2024": "https://data.insideairbnb.com/united-kingdom/england/london/2024-09-06/visualisations/listings.csv",
        "file_name": "Airbnb-listings-2024.csv",
        "dataset_name": "Airbnb-listings-2024",
        "scrape_year": 2024
    },
    {
        "url2022": "https://orca.casa.ucl.ac.uk/~jreades/data/2022-09-10-listings.csv.gz",
        "file_name": "2022-09-10-listings.csv.gz",
        "dataset_name": "Airbnb-listings-2022",
        "scrape_year": 2022
    },
    {
        "url2023": "https://orca.casa.ucl.ac.uk/~jreades/data/2023-09-06-listings.csv.gz",
        "file_name": "2023-09-06-listings.csv.gz",
        "dataset_name": "Airbnb-listings-2023",
        "scrape_year": 2023
    }
]

# Define output directory
output_folder = os.path.join("Double-Win-Files", "Airbnb-Data")
os.makedirs(output_folder, exist_ok=True)

def download_and_load_dataset(dataset):
    """Downloads and loads a dataset into a pandas DataFrame."""
    url_key = [key for key in dataset.keys() if key.startswith("url")][0]
    url = dataset[url_key]
    file_name = dataset['file_name']
    file_path = os.path.join(output_folder, file_name)

    # Check if file already exists
    if not os.path.exists(file_path):
        print(f"Downloading {file_name} from {url}...")
        response = requests.get(url)
        response.raise_for_status()

        # Save the downloaded file 
        with open(file_path, 'wb') as f:
            f.write(response.content)
    else:
        print(f"{file_name} already exists. Loading from file.")

    # Load the dataset from the local file
    if file_name.endswith('.gz'):
        with gzip.open(file_path, 'rt') as gz_file:
            df = pd.read_csv(gz_file, low_memory=False)
    else:
        df = pd.read_csv(file_path, low_memory=False)

    return df

def clean_dataset(df):
    """
    Cleans the dataset by removing duplicates, rows with blanks in required columns,
    and ensuring proper data types with defaults where needed.
    """
    # Define expected data types and default values for each column
    dtype_mapping = {
        'id': ('Int64', 0),
        'host_id': ('Int64', 0),
        'latitude': ('float64', 0.0),
        'longitude': ('float64', 0.0),
        'last_review': ('string', '01/01/1970'),
        'availability_365': ('Int64', 0),
        'room_type': ('string', 'unknown')
    }

    required_columns = dtype_mapping.keys()

    # Ensure only the required columns are considered
    df = df[list(required_columns)]

    # Remove rows with blanks (NaN) in any of the required columns
    df = df.dropna(subset=required_columns, how='any')

    # Remove duplicate rows
    df = df.drop_duplicates()

    # Process each column according to its expected data type and default value
    for col, (expected_type, default_value) in dtype_mapping.items():
        if col == 'last_review':
            df[col] = pd.to_datetime(df[col], errors='coerce').fillna(pd.Timestamp(default_value)).dt.strftime('%d/%m/%Y')
        elif col == 'room_type':
            df[col] = df[col].astype('string').fillna(default_value)
        else:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(default_value).astype(expected_type)

    return df

def process_and_save_dataset(dataset):
    """Processes a dataset, cleans it, and saves only specific columns."""
    try:
        df = download_and_load_dataset(dataset)

        # Clean the dataset
        df = clean_dataset(df)

        # Add scrape_year column
        df['scrape_year'] = dataset['scrape_year']

        # Construct the output file name using `dataset_name`
        output_file = os.path.join(output_folder, f"{dataset['dataset_name']}_processed.csv")
        df.to_csv(output_file, index=False)

        print(f"Processed and saved: {output_file}")

    except Exception as e:
        print(f"An error occurred while processing {dataset['dataset_name']}: {e}")

# Process each dataset
for dataset in datasets:
    process_and_save_dataset(dataset)

# Download or verify the shapefile exists
shapefile_url = "https://api.os.uk/downloads/v1/products/BoundaryLine/downloads?area=GB&format=ESRI%C2%AE+Shapefile&redirect"
download_folder = os.path.join("Double-Win-Files", "UK-Borough-Boundary-Data")
shapefile_dir = os.path.join(download_folder, "Data/GB")
shapefile_path = os.path.join(shapefile_dir, "district_borough_unitary_region.shp")

def download_shapefile(url, download_dir, shapefile_path):
    # Check if the directory exists, create it if not
    if not os.path.exists(download_dir):
        os.makedirs(download_dir)
        print(f"Created directory: {download_dir}")
    
    # Check if the shapefile already exists
    if os.path.exists(shapefile_path):
        print(f"Shapefile already exists at {shapefile_path}")
        return shapefile_path
    
    # Download the data
    print(f"Downloading shapefile from {url}...")
    response = requests.get(url, stream=True)
    response.raise_for_status()
    
    # Save the zip file
    zip_file_path = os.path.join(download_dir, "BoundaryLine.zip")
    with open(zip_file_path, "wb") as f:
        f.write(response.content)
    print(f"Downloaded and saved as {zip_file_path}")
    
    # Extract the zip file
    import zipfile
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(download_dir)
    print(f"Extracted shapefile to {download_dir}")
    
    # Return path to shapefile
    return shapefile_path

shapefile_path = download_shapefile(shapefile_url, download_folder, shapefile_path)

# Load the shapefile into a GeoDataFrame
shapefile_gdf = gpd.read_file(shapefile_path)

lbo_gdf = shapefile_gdf[shapefile_gdf['AREA_CODE'] == 'LBO']

def filter_airbnb_by_boroughs(df, shapefile_gdf):
    """Filters Airbnb data by checking if the points are within the London Boroughs."""
    # Convert the DataFrame to a GeoDataFrame based on latitude and longitude
    df_gdf = gpd.GeoDataFrame(
        df, geometry=gpd.points_from_xy(df.longitude, df.latitude),
        crs="EPSG:4326"
    )

    # Reproject the Airbnb GeoDataFrame to match the shapefile's CRS (EPSG:27700)
    df_gdf = df_gdf.to_crs(epsg=27700)

    # Reproject the shapefile GeoDataFrame to EPSG:27700 if not already in that CRS
    shapefile_gdf = shapefile_gdf.to_crs(epsg=27700)

    # Use union_all() instead of unary_union to get all the borough polygons combined
    borough_union = shapefile_gdf.geometry.union_all()

    # Add Borough column by checking within which borough the point is located
    borough_names = []
    for _, row in df_gdf.iterrows():
        borough_name = shapefile_gdf[shapefile_gdf.geometry.contains(row['geometry'])]['NAME'].values
        borough_names.append(borough_name[0] if borough_name.size > 0 else 'Unknown')

    df_gdf['Borough'] = borough_names

    # Remove 'London Boro' using regex
    df_gdf['Borough'] = df_gdf['Borough'].apply(lambda x: re.sub(r'\s*London\s*Boro\s*', '', x, flags=re.IGNORECASE))

    # Replace specific borough names
    df_gdf['Borough'] = df_gdf['Borough'].replace({
        'City and County of the City of London': 'City of London',
        'City of Westminster': 'Westminster'
    })

    # Drop the geometry column, as we no longer need it
    df_gdf = df_gdf.drop(columns=['geometry'])

    return df_gdf, shapefile_gdf

def combine_processed_datasets(input_folder, output_file, shapefile_gdf):
    """Combines all processed datasets into a single DataFrame, filters by London Boroughs, and saves it."""
    all_files = [
        f"{dataset['dataset_name']}_processed.csv" for dataset in datasets
    ]

    combined_df = pd.DataFrame()

    for file in all_files:
        file_path = os.path.join(input_folder, file)
        print(f"Loading {file_path}...")

        # Load the dataset and add a source column
        df = pd.read_csv(file_path)
        print(f"Columns in {file_path}: {df.columns}")

        # Filter the data to only include listings within London Boroughs and add the Borough column
        filtered_df, _ = filter_airbnb_by_boroughs(df, shapefile_gdf)

        # Debug: Check columns in filtered DataFrame
        print(f"Columns in filtered_df: {filtered_df.columns}")
        
        combined_df = pd.concat([combined_df, filtered_df], ignore_index=True)

    # Debug: Check columns before applying room_type filter
    print("Columns in combined DataFrame before filtering:", combined_df.columns)

    if 'room_type' not in combined_df.columns:
        print("Error: 'room_type' column is missing in combined DataFrame!")
    else:
        combined_df = combined_df[combined_df['room_type'] == 'Entire home/apt']

    # Print the first few rows of combined_df to verify its content
    print("First few rows of combined_df:")
    print(combined_df.head())

    # Save the combined dataset
    combined_df.to_csv(output_file, index=False)
    return combined_df

# Define output file for the combined dataset
output_combined_file = os.path.join(output_folder, "Airbnb_combined_dataset.csv")

# Combine and filter datasets, then save the result
combined_df = combine_processed_datasets(output_folder, output_combined_file, lbo_gdf)
